{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2f678e-5d43-4f9e-9caa-1d172a3b7ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with\n",
    "an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217a03bc-67f8-4f1f-a19d-362c05b3f098",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Probability Mass Function (PMF) and Probability Density Function (PDF) are mathematical functions used in\n",
    "probability theory and statistics to describe the probability distribution of discrete and continuous random variables, respectively.\n",
    "\n",
    "Probability Mass Function (PMF):\n",
    "\n",
    "The PMF is used for discrete random variables, which take on a countable set of possible values.\n",
    "The PMF gives the probability of each possible outcome or value of the random variable.\n",
    "The PMF is typically denoted as P(X = x), where X is the random variable and x is a specific value of X.\n",
    "The PMF satisfies two properties: 1) The probability for any value is non-negative, and 2) The sum of the probabilities for all possible\n",
    "values is equal to 1.\n",
    "Example: Consider rolling a fair six-sided die. The PMF of this discrete random variable is given by\n",
    "P(X = 1) = 1/6, P(X = 2) = 1/6, P(X = 3) = 1/6, P(X = 4) = 1/6, P(X = 5) = 1/6, and P(X = 6) = 1/6. \n",
    "Each value has an equal probability of 1/6.\n",
    "\n",
    "Probability Density Function (PDF):\n",
    "\n",
    "The PDF is used for continuous random variables, which can take on an infinite number of possible values within a given range.\n",
    "The PDF represents the relative likelihood of the random variable taking on different values within a range.\n",
    "The PDF is denoted as f(x), where x is a specific value within the range of the random variable.\n",
    "Unlike the PMF, the PDF does not directly give the probability at a specific value. Instead, the probability is obtained by integrating the\n",
    "PDF over a range of values.\n",
    "The PDF satisfies two properties: 1) The probability density for any value is non-negative, and 2) The integral of the PDF over the\n",
    "entire range of values is equal to 1.\n",
    "Example: The PDF of a standard normal distribution (mean = 0, standard deviation = 1) is given by the equation\n",
    "f(x) = (1 / √(2π)) * e^(-x^2/2), where e is the base of the natural logarithm and π is a mathematical constant. The PDF represents the \n",
    "relative likelihood of different values of the random variable occurring in the standard normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9d455f-5f92-43d9-a29a-58dd14ba3b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d267b8ec-7de2-43cc-999c-46c550c960b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Cumulative Density Function (CDF) is a mathematical function that describes the cumulative probability distribution of a random \n",
    "variable. It gives the probability that a random variable takes on a value less than or equal to a specific value. The CDF provides\n",
    "information about the likelihood of a random variable falling within a certain range.\n",
    "\n",
    "Mathematically, the CDF is defined as:\n",
    "CDF(x) = P(X ≤ x)\n",
    "\n",
    "Here, X is the random variable and x is a specific value within the range of X. The CDF gives the probability that the random variable \n",
    "X is less than or equal to x.\n",
    "\n",
    "The CDF has the following properties:\n",
    "\n",
    "Non-decreasing: The CDF is a monotonically increasing function, meaning that as x increases, the probability of X being less than or equal\n",
    "to x also increases.\n",
    "Bounded: The CDF is bounded between 0 and 1, meaning that the probability of X being less than or equal to any value is always between 0\n",
    "and 1.\n",
    "Right-continuous: The CDF is right-continuous, which means that the limit of the CDF as x approaches a specific value from the right side \n",
    "is equal to the probability of X being less than or equal to that value.\n",
    "The CDF is used for various purposes in probability theory and statistics, including:\n",
    "\n",
    "Determining probabilities: The CDF allows us to calculate probabilities of a random variable falling within a specific range. By evaluating \n",
    "the CDF at different values, we can determine the probability of X being less than or equal to a certain value or falling within a specific\n",
    "interval.\n",
    "Finding percentiles: The CDF enables us to determine percentiles, such as the median or quartiles, of a random variable. By finding the \n",
    "value of x for which CDF(x) is equal to a given probability, we can identify the corresponding percentile.\n",
    "Comparing distributions: The CDF can be used to compare different probability distributions. By comparing their CDFs, we can assess how \n",
    "the probabilities are distributed across different values and identify any differences or similarities between the distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3a1f79-1a63-4677-9ef3-8fd26cc45682",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3: What are some examples of situations where the normal distribution might be used as a model?\n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6af3444-222d-406d-9603-9d710ef32da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "The normal distribution, also known as the Gaussian distribution or bell curve, is a widely used probability distribution in various fields. It is often employed as a model in situations where the data exhibit characteristics such as symmetry, clustering around a central value, and a predictable spread.\n",
    "\n",
    "Here are some examples of situations where the normal distribution might be used as a model:\n",
    "\n",
    "Height: The distribution of human heights tends to follow a normal distribution, with most people clustered around the average height and \n",
    "fewer individuals at the extreme ends (very tall or very short). This makes the normal distribution a suitable model for studying \n",
    "height-related phenomena.\n",
    "\n",
    "IQ Scores: Intelligence quotient (IQ) scores are often modeled using a normal distribution. The distribution of IQ scores is typically\n",
    "centered around the average score, with fewer individuals having very high or very low scores.\n",
    "\n",
    "Measurement Errors: In many scientific experiments and observations, there can be measurement errors due to various factors. Assuming \n",
    "these errors follow a normal distribution is often reasonable, as it implies that most errors are small, with fewer large errors occurring.\n",
    "\n",
    "Financial Markets: Many financial models assume that returns on investments or stock prices follow a normal distribution. While this \n",
    "assumption is not always perfect due to market complexities, the normal distribution provides a useful approximation in many cases.\n",
    "\n",
    "The normal distribution is characterized by two parameters: mean (μ) and standard deviation (σ). These parameters determine the shape\n",
    "and characteristics of the distribution:\n",
    "\n",
    "Mean (μ): The mean determines the central value or the average of the distribution. It corresponds to the peak or center of the bell curve. \n",
    "Shifting the mean to the right or left will shift the entire distribution along the x-axis.\n",
    "\n",
    "Standard Deviation (σ): The standard deviation measures the spread or variability of the data around the mean. It determines the width of \n",
    "the distribution. A larger standard deviation results in a broader and flatter bell curve, indicating more dispersion of the data. \n",
    "Conversely, a smaller standard deviation leads to a narrower and taller bell curve, indicating less dispersion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc2e415-64a8-43b1-8409-42f4fc66dd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal\n",
    "Distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4118a74f-07b5-4008-8ba3-65afc5e25682",
   "metadata": {},
   "outputs": [],
   "source": [
    "The normal distribution, also known as the Gaussian distribution or bell curve, is of great importance in statistics and probability \n",
    "theory. It has several key characteristics that make it widely used and applicable in various real-life scenarios. Here are some reasons \n",
    "for the importance of the normal distribution:\n",
    "\n",
    "Central Limit Theorem: The normal distribution is closely related to the Central Limit Theorem, which states that the sum or average of a\n",
    "large number of independent and identically distributed random variables will be approximately normally distributed, regardless of the \n",
    "underlying distribution of the individual variables. This theorem is fundamental in statistical inference and allows us to make robust \n",
    "inferences about population parameters based on sample data.\n",
    "\n",
    "Symmetry and Central Tendency: The normal distribution is symmetric, with the mean, median, and mode all located at the center of the \n",
    "distribution. This symmetry makes it a suitable model for variables that tend to cluster around a central value, such as physical \n",
    "measurements like height, weight, and IQ scores.\n",
    "\n",
    "Universality: The normal distribution arises in numerous natural and social phenomena due to the combined effects of many small, \n",
    "independent, and random factors. As a result, it is often considered a default or baseline distribution for many variables in the\n",
    "absence of specific evidence to the contrary.\n",
    "\n",
    "Real-life examples of situations where the normal distribution can be observed include:\n",
    "\n",
    "Heights of a population: The distribution of human heights often follows a normal distribution, with most individuals clustering around \n",
    "the average height and fewer individuals at the extreme ends (very tall or very short).\n",
    "\n",
    "Test scores: Standardized tests, such as SAT or IQ tests, are designed to have a normal distribution of scores. The scores are typically \n",
    "centered around the average, with fewer individuals achieving very high or very low scores.\n",
    "\n",
    "Errors in measurements: When measuring physical quantities or conducting scientific experiments, measurement errors often follow a normal \n",
    "distribution. This assumption allows for effective modeling and statistical analysis of the errors.\n",
    "\n",
    "Financial markets: Many financial models assume that returns on investments or stock prices follow a normal distribution. While this \n",
    "assumption is not always perfect due to market complexities, it provides a useful approximation in many cases.\n",
    "\n",
    "Natural phenomena: Various natural phenomena, such as the distribution of rainfall, errors in weather predictions, or the distribution \n",
    "of biological traits, can often be approximated by a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de1630-d6c9-4866-8e21-a5894f07a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli\n",
    "Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec121cf9-5aeb-4049-a4d2-9bc3c2cb5068",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Bernoulli distribution is a discrete probability distribution that models a random experiment with two possible outcomes: success \n",
    "(usually denoted as 1) and failure (usually denoted as 0). It is named after Swiss mathematician Jacob Bernoulli. The distribution is \n",
    "characterized by a single parameter, p, which represents the probability of success.\n",
    "\n",
    "The probability mass function (PMF) of the Bernoulli distribution is given by:\n",
    "\n",
    "P(X = x) = p^x * (1-p)^(1-x)\n",
    "\n",
    "where X is the random variable representing the outcome (0 or 1), and x can take values 0 or 1.\n",
    "\n",
    "Example:\n",
    "An example of the Bernoulli distribution is flipping a fair coin. Suppose we define success as getting heads (H) and failure as getting \n",
    "tails (T). The probability of getting heads, p, is 0.5, and the probability of getting tails, 1-p, is also 0.5. Thus, the Bernoulli \n",
    "distribution can be used to model this scenario, where the outcome is either a success (H) or a failure (T).\n",
    "\n",
    "Difference between Bernoulli Distribution and Binomial Distribution:\n",
    "\n",
    "Number of Trials: In the Bernoulli distribution, there is only a single trial or experiment with two possible outcomes. In contrast, \n",
    "the binomial distribution involves a fixed number of independent and identical Bernoulli trials.\n",
    "\n",
    "Number of Successes: The Bernoulli distribution focuses on a single success or failure, whereas the binomial distribution allows for\n",
    "multiple successes or failures. The binomial distribution represents the number of successes, k, out of a fixed number of trials, n.\n",
    "\n",
    "Parameters: The Bernoulli distribution has a single parameter, p, which represents the probability of success in a single trial.\n",
    "On the other hand, the binomial distribution has two parameters: n, the number of trials, and p, the probability of success in each trial.\n",
    "\n",
    "Probability Mass Function (PMF): The PMF of the Bernoulli distribution considers a specific outcome (0 or 1). In contrast, the PMF of the \n",
    "binomial distribution calculates the probability of obtaining a specific number of successes (k) out of a fixed number of trials (n).\n",
    "\n",
    "Shape: The Bernoulli distribution is a discrete distribution, as it deals with only two possible outcomes. The binomial distribution is \n",
    "also discrete, but it describes the distribution of the number of successes, which can take on multiple discrete values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d71a804-d582-46e7-97c6-43597b1aee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater\n",
    "than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288edad0-8860-43c6-81cd-50b75f56c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "To calculate the probability that a randomly selected observation from a normally distributed dataset will be greater than 60, we can\n",
    "use the standard normal distribution and the Z-score.\n",
    "\n",
    "The Z-score represents the number of standard deviations a value is away from the mean. We can calculate the Z-score using the formula:\n",
    "\n",
    "Z = (X - μ) / σ\n",
    "\n",
    "Where:\n",
    "X is the value we want to find the probability for (in this case, 60)\n",
    "μ is the mean of the dataset\n",
    "σ is the standard deviation of the dataset\n",
    "Given:\n",
    "\n",
    "X = 60\n",
    "μ = 50\n",
    "σ = 10\n",
    "Calculating the Z-score:\n",
    "\n",
    "Z = (60 - 50) / 10\n",
    "Z = 1\n",
    "\n",
    "Next, we can look up the probability corresponding to the Z-score of 1 in the standard normal distribution table or use statistical\n",
    "software. The probability will be the area under the curve to the right of the Z-score.\n",
    "\n",
    "Using a standard normal distribution table, we find that the probability corresponding to a Z-score of 1 is approximately 0.8413.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation will be greater than 60, assuming a normal distribution with a mean\n",
    "of 50 and a standard deviation of 10, is approximately 0.8413 or 84.13%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8d68ec-ae75-4976-8d8c-d8154507538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503c7147-7e87-40e2-90d7-71d950c31fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "The uniform distribution is a probability distribution in which all outcomes or values within a given range have equal likelihood of \n",
    "occurring. It is also known as the rectangular distribution due to its constant probability density function (PDF) over the entire range.\n",
    "\n",
    "In a uniform distribution, every possible outcome is equally likely, and the shape of the distribution is a constant, flat line.\n",
    "The PDF of a uniform distribution is defined as:\n",
    "\n",
    "f(x) = 1 / (b - a)\n",
    "\n",
    "where:\n",
    "f(x) is the probability density function\n",
    "a is the lower bound of the range\n",
    "b is the upper bound of the range\n",
    "The cumulative distribution function (CDF) for the uniform distribution is a linear function that increases uniformly from 0 to 1 over \n",
    "the range.\n",
    "\n",
    "Example:\n",
    "Let's consider an example of a uniform distribution where we have a fair six-sided die. The outcomes of rolling the die can be represented\n",
    "by the numbers 1, 2, 3, 4, 5, and 6. Each outcome has an equal probability of occurring, which is 1/6 since the die is fair.\n",
    "\n",
    "In this case, the range of the uniform distribution is from 1 to 6. The probability density function (PDF) is constant within this \n",
    "range and equal to 1/6. Therefore, the PDF for each outcome is:\n",
    "\n",
    "f(x) = 1 / (6 - 1) = 1/5\n",
    "\n",
    "The cumulative distribution function (CDF) for the uniform distribution will be a linear function that increases uniformly from 0 to 1 \n",
    "over the range of 1 to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ed527e-d20e-4f1f-b470-99989a3a717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f97a38-4fb5-4e80-98be-384f55b3c086",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Z-score, also known as the standard score, is a statistical measure that indicates how many standard deviations a data point is away \n",
    "from the mean of a distribution. It is calculated using the formula:\n",
    "\n",
    "Z = (X - μ) / σ\n",
    "\n",
    "where:\n",
    "\n",
    "Z is the Z-score\n",
    "X is the data point\n",
    "μ is the mean of the distribution\n",
    "σ is the standard deviation of the distribution\n",
    "The Z-score tells us how far a data point is from the mean in terms of standard deviations. A positive Z-score indicates that the data \n",
    "point is above the mean, while a negative Z-score indicates that it is below the mean.\n",
    "\n",
    "Importance of the Z-score:\n",
    "\n",
    "Standardization: The Z-score is a method of standardizing data, allowing for comparisons between different datasets with different scales \n",
    "and distributions. By transforming data into Z-scores, we can directly compare observations from different populations or variables.\n",
    "\n",
    "Normal Distribution: The Z-score is particularly useful in the context of the normal distribution. For a normally distributed dataset,\n",
    "we can use Z-scores to determine the proportion or probability associated with a specific value or range. This enables us to make\n",
    "comparisons, identify outliers, and calculate percentiles.\n",
    "\n",
    "Outlier Detection: Z-scores are commonly used to identify outliers in a dataset. Data points with Z-scores that fall outside a certain\n",
    "threshold (e.g., beyond ±2 or ±3 standard deviations) are considered unusual and may be flagged as outliers.\n",
    "\n",
    "Hypothesis Testing: Z-scores are crucial in hypothesis testing and determining the statistical significance of results. By comparing \n",
    "observed Z-scores to critical values, we can assess whether a sample is significantly different from the population or if an effect is \n",
    "statistically significant.\n",
    "\n",
    "Data Analysis and Interpretation: Z-scores provide a standardized measure of how unusual or extreme a data point is within a distribution. \n",
    "They help in interpreting and communicating the relative position and significance of individual data points within a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d56e76-5874-4726-9dfd-8e3bf234ac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that states that when independent random variables are added, their \n",
    "sum tends to follow a normal distribution, regardless of the shape of the original distribution, as long as the sample size is sufficiently\n",
    "large.\n",
    "\n",
    "The Central Limit Theorem states that the sum or average of a large number of independent and identically distributed random variables \n",
    "will have an approximately normal distribution, regardless of the shape of the original distribution. This holds true even if the\n",
    "individual variables themselves are not normally distributed.\n",
    "\n",
    "Significance of the Central Limit Theorem:\n",
    "\n",
    "Normality Approximation: The Central Limit Theorem allows us to approximate the distribution of sample means or sums as a normal \n",
    "distribution. This is crucial because the normal distribution is well understood and has many useful properties. It enables the use of \n",
    "various statistical techniques that are based on the assumption of normality, such as hypothesis testing, confidence intervals, and \n",
    "parameter estimation.\n",
    "\n",
    "Real-world Applications: The Central Limit Theorem is widely applicable in various fields and industries. It provides a foundation for \n",
    "statistical inference and helps in analyzing and interpreting data in areas such as finance, economics, social sciences, quality control,\n",
    "and more. It allows researchers and analysts to make reliable inferences about a population based on a sample.\n",
    "\n",
    "Sample Size Determination: The Central Limit Theorem plays a crucial role in sample size determination. It states that as long as the\n",
    "sample size is sufficiently large, the distribution of the sample mean will be approximately normal. This information helps in determining \n",
    "the appropriate sample size to achieve desired levels of precision and reliability in statistical analyses.\n",
    "\n",
    "Robustness to Non-Normality: The Central Limit Theorem provides a level of robustness in statistical analyses. Even if the population \n",
    "distribution is not normal, as long as the sample size is large enough, the distribution of sample means will tend to follow a normal \n",
    "distribution. This allows for the use of parametric statistical tests that assume normality, even in situations where the underlying data \n",
    "may not be normally distributed.\n",
    "\n",
    "Foundations of Inferential Statistics: The Central Limit Theorem is a cornerstone of inferential statistics. It provides a theoretical \n",
    "basis for hypothesis testing, confidence intervals, and other statistical procedures that rely on the assumption of normality. It allows \n",
    "researchers to draw conclusions about populations based on sample data and make statistical inferences with confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60460e0-313a-42e9-9e09-2fe6713d5b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85577a97-f423-49a4-828e-de328c538db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Central Limit Theorem (CLT) relies on several assumptions to hold true. These assumptions include:\n",
    "\n",
    "Independent and Identically Distributed (IID) Random Variables: The underlying random variables in the sample must be independent of each \n",
    "other, meaning that the value of one random variable does not affect the value of another. Additionally, the random variables must be \n",
    "identically distributed, meaning they have the same probability distribution.\n",
    "\n",
    "Finite Mean and Variance: The random variables must have a finite mean (μ) and a finite variance (σ^2). This assumption ensures that the\n",
    "mean and variance of the sample mean or sum can be well-defined.\n",
    "\n",
    "Sufficiently Large Sample Size: The Central Limit Theorem holds as the sample size (n) increases. While there is no strict threshold for\n",
    "what constitutes a \"sufficiently large\" sample size, a commonly cited rule of thumb is that n should be at least 30. However, the exact \n",
    "sample size requirement may vary depending on the distribution of the original data.\n",
    "\n",
    "No Heavy-Tailed Distributions: The Central Limit Theorem assumes that the original distribution does not have heavy tails. Heavy-tailed \n",
    "distributions, such as the Cauchy distribution, do not satisfy the requirements for the CLT. In such cases, alternative approaches, \n",
    "such as the Stable Central Limit Theorem, may be used"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
